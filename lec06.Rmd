---
title: "STA286 Lecture 06"
author: "Neil Montgomery"
date: "Last edited: `r format(Sys.time(), '%Y-%m-%d %H:%M')`"
output: 
  beamer_presentation:
    keep_tex: TRUE
    incremental: TRUE
    df_print: tibble
    fig_caption: FALSE
classoption: aspectratio=169
header-includes:
- \renewcommand{\le}{\leqslant}
- \renewcommand{\ge}{\geqslant}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
options(tibble.width=70)
```

## cumulative distribution functions

**All** random variables have a cumulative distribution function, defined as follows for an r.v. named $X$:
$$F(x) = P(X \le x)$$

You could make a picture of a cdf.

\pause Example: Toss a coin; map `H` to 1 and `T` to 0, calling the map $X$. Then:
$$F(x) = \begin{cases}
\onslide<3->{0 &: x < 0\\}
\onslide<4->{0.5 &: 0 \le x < 1\\}
\onslide<5->{1 &: x \ge 1}
\end{cases}$$

## picture of cdf

```{r, message=FALSE, warning=FALSE}
source("cdf.R")
plot_cdf(data_frame(x=0:1, y=c(0.5,0.5)))

```


## defining properties of a cdf

A function is a cdf if and only if:

1. $\lim\limits_{x\to-\infty} F(x) = 0$ ("Starts at 0")

2. $\lim\limits_{x\to+\infty} F(x) = 1$ ("Ends at 1")

3. it is non-decreasing, i.e. $x \le y$ implies $F(x) \le F(y)$

4. it is "right-continuous" (technical definition: $\lim\limits_{x\to x_0^+} F(x) = F(x_0)$)

\pause Example: waiting for the bus for between 0 and 10 minutes "uniformly".

\pause $$F(x) = \begin{cases}
0 &: x < 0\\
x/10 &: 0 \le x < 10\\
1 &: x \ge 10
\end{cases}$$
\pause Equality vs. inequality not really important in a "continuous" probability model.

## picture of this cdf

```{r}
data_frame(x=c(-2.618, 0, 10, 12.618), y=c(0,0,1,1)) %>% 
  ggplot(aes(x=x,y=y)) + geom_line() + 
  geom_segment(x=-2.618, y=0, xend=0, yend=0, 
               arrow=arrow(length=unit(0.15, "inches"), 
                             ends="first", type = "closed")) + 
  geom_segment(x=10, y=1, xend=12.618, yend=1, 
               arrow=arrow(length=unit(0.15, "inches"), 
                             ends="last", type = "closed")) + 
  ylab(expression(P(X <= x))) + 
    theme_classic() + 
    theme(axis.text = element_text(size=14, colour="black"),
          axis.title = element_text(size=14, face="bold"))

```


## a taxonomy of random variables

It is possible to classify random variables:

1. \textit{discrete} random variables take on a finite or countably infinite number of outcomes.
    + its cdf will be a \textit{step function}
2. \textit{continuous} random variables take on values in intervals
    + its cdf will be a \textit{continuous function}
3. Neither discrete nor continuous.

\pause As an example of the latter, consider the time-to-failure of an electronic component that:

* fails immediately the first time you try it, with probability $0.01$

* works immediately with probability $0.99$ and subsequently fails according to some continuous probability model TBA.

## discrete random variables

CDFs are nice because *all* random variables have one, but they aren't the most natural representations of distributions.

For a discrete random variable $X$, the function that maps the individual outcomes to their probabilities is more natural.

\pause Example: Let $X$ be the number of tosses of a coin until the first `H` appears. This function maps individual outcomes to probabilities:
$$p(x) = f(x) = P(X=x) = \left(\frac{1}{2}\right)^x, \quad x \in \{1,2,3,\ldots\}$$

\pause Such a function is (best) called a *probability mass function* or pmf. I tend to use $p(x)$ notation for pmfs.

\pause Textbook notes: the book uses $f(x)$ notation, which I dislike. It also gives the following (terrible) synonyms:

* "probability function" (name already taken by $P$!)

* "probability distribution" (name already being used for a fundamental concept!)

## more pmf examples

**See if a product is defective:** A factory makes a defective item with probability $p$. Select an item at random from a factory. Let $X=1$ if the item is defective, and let $X=0$ otherwise. 

\pause The pmf of $X$ is:
$$p(x) = P(X = x) = \begin{cases}
p &: x=1\\
1-p &: x=0
\end{cases}$$

\pause More compact version: $p(x) = p^x(1-p)^{1-x}$

## defining properties of pmf

A function $p(x)$ is a pmf if and only if:

1. $$p(x) \ge 0$$
2. $$\sum\limits_{\{x\,|\,P(X=x) > 0\}} p(x) = 1$$

## checking if a function is a valid pmf

I said this function is a pmf. Is it?
$$p(x) = f(x) = P(X=x) = \left(\frac{1}{2}\right)^x, \quad x \in \{1,2,3,\ldots\}$$

Verify:

1. $p(x) \ge 0$

2. Fact: $\sum\limits_{x=0}^\infty ar^x = \frac{a}{1-r}$ for $0 < r < 1$. So:
$$\sum\limits_{x=1}^\infty \left(\frac{1}{2}\right)^x = \sum\limits_{x=0}^\infty \frac{1}{2}\left(\frac{1}{2}\right)^x = 1$$

## a pmf completely characterizes a discrete distribution

I told you a cdf completely characterizes any distribution, which is a fact you'll have to take on buffy. 

\pause A discrete random variable has a pmf. Does the pmf characterize the distribtuion? 

\pause Yes, because you can compute a cdf from a pdf and vice versa. "Obviously:"
$$F(x) = \sum\limits_{y\le x} p(y)$$
For the reverse direction you take the jump points of the cdf and determine the magnitude of the jump.

## possibly easier to see than to understand the formal statement

```{r, warning=FALSE}
p <- plot_cdf(data_frame(x=1:6, y=(0.5)^(1:6)))

p + 
  geom_segment(data=data_frame(x=1:6, y=1-0.5^(0:5), xend=1:6,yend=1-(0.5)^(1:6)),
               mapping=aes(x=x, y=y,
                           xend=xend,yend=yend), colour="blue", size=1.5, alpha=0.5) +
  annotate("text", x=1:4-0.5 , y=(1-0.5^(1:4) - 0.5^(1:4)/2), label=sprintf("P(X=%d)", 1:4), color="blue")
  
```




